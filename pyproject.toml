[project]
name = "inference-benchmark"
dynamic = ["version"]
description = "machine learning model serving benchmark"
authors = [{ name = "TensorChord", email = "modelz@tensorchord.ai" }]
keywords = ["machine learning", "deep learning", "model serving"]
classifiers = [
    "Intended Audience :: Developers",
    "Topic :: Scientific/Engineering :: Artificial Intelligence",
]
dependencies = [
    "torch",
    "transformers",
    "numpy",
    "soundfile",
    "diffusers",
    "mosec",
]
requires-python = ">=3.8"
readme = "README.md"
license = { text = "Apache-2.0" }

[project.urls]
"Homepage" = "https://github.com/tensorchord/inference-benchmark"

[project.scripts]
inference-benchmark = ""

[project.optional-dependencies]
dev = [
    "black",
    "ruff",
]

[build-system]
requires = ["setuptools", "setuptools_scm>=7.0"]
build-backend = "setuptools.build_meta"

[tool.setuptools_scm]
write_to = "src/_version.py"

[tool.ruff]
target-version = "py38"
line-length = 88
select = ["E", "F", "B", "I", "SIM", "TID", "PL"]
[tool.ruff.pylint]
max-branches = 35
max-statements = 100

[tool.black]
line-length = 88
